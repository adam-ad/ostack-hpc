Create an empty chpc\_init file and open for editing. You can also use  existing template and modify.

Start editing by adding some environment variable, first one is to set path to shared folder for cloud-init

% begin_ohpc_run
% ohpc_validation_newline
% ohpc_validation_comment #   XFILEX # prepare_cloud_init
\begin{lstlisting}[language=bash,keywords={}]
[ctrlr](*\#*)chpcInitPath=/opt/ohpc/admin/cloud_hpc_init
[ctrlr](*\#*)logger "chpcInit: Updating Compute Node with HPC configuration"
\end{lstlisting}
%end_ohpc_run

Update rsyslog configuration file to send all the syslog to sms. sms\_ip is the tag used here is updated with IP of SMS node just before provisioning.

% begin_ohpc_run
% ohpc_validation_newline
\begin{lstlisting}[language=bash,keywords={}]
[ctrlr](*\#*)  Update rsyslog
[ctrlr](*\#*) cat /etc/rsyslog.conf | grep "<sms_ip>:514"
[ctrlr](*\#*) rsyslog_set=$?
[ctrlr](*\#*) if [ "${rsyslog_set}" -ne "0" ]; then
[ctrlr](*\#*)    echo "*.* @<sms_ip>:514" >> /etc/rsyslog.conf
[ctrlr](*\#*) fi
[ctrlr](*\#*) systemctl restart rsyslog
[ctrlr](*\#*) logger "chpcInit: rsyslog configuration complete, updating remaining HPC configuration"
\end{lstlisting}
%end_ohpc_run

Assuming sms node nfs share /home, /opt/ohpc/pub, =/opt/ohpc/admin/cloud\_hpc\_init lets mount them during boot

% begin_ohpc_run
% ohpc_validation_newline
\begin{lstlisting}[language=bash,keywords={}]
[ctrlr](*\#*) # nfs mount directory from SMS head node to Compute Node
[ctrlr](*\#*) cat /etc/fstab | grep "<sms_ip>:/home"
[ctrlr](*\#*) home_exists=$?
[ctrlr](*\#*) if [ "${home_exists}" -ne "0" ]; then
[ctrlr](*\#*)     echo "<sms_ip>:/home /home nfs nfsvers=3,rsize=1024,wsize=1024,cto 0 [ctrlr](*\#*) 0" >> /etc/fstab
[ctrlr](*\#*) fi
[ctrlr](*\#*) cat /etc/fstab | grep "<sms_ip>:/opt/ohpc/pub"
[ctrlr](*\#*) ohpc_pub_exists=$?
[ctrlr](*\#*) 
[ctrlr](*\#*) if [ "${ohpc_pub_exists}" -ne "0" ]; then
[ctrlr](*\#*)     echo "<sms_ip>:/opt/ohpc/pub /opt/ohpc/pub nfs nfsvers=3 0 0" >> /etc/fstab
[ctrlr](*\#*)     # Make sure we have directory to mount
[ctrlr](*\#*)     # Clean up if required
[ctrlr](*\#*)     if [ -e /opt/ohpc/pub ]; then
[ctrlr](*\#*)         echo "chpcInit: [WARNING] /opt/ohpc/pub already exists!!"
[ctrlr](*\#*)     fi
[ctrlr](*\#*) fi
[ctrlr](*\#*) mkdir -p /opt/ohpc/pub
[ctrlr](*\#*) mount /home
[ctrlr](*\#*) mount /opt/ohpc/pub
[ctrlr](*\#*) 
[ctrlr](*\#*) # Mount cloud_hpc_init
[ctrlr](*\#*) cat /etc/fstab | grep "sms_ip:$chpcInitPath"
[ctrlr](*\#*) CloudHPCInit_exist=$?
[ctrlr](*\#*) if [ "${CloudHPCInit_exist}" -ne "0" ]; then
[ctrlr](*\#*)     echo "<sms_ip>:$chpcInitPath $chpcInitPath nfs nfsvers=3 0 0" >> /etc/fstab
[ctrlr](*\#*) fi
[ctrlr](*\#*) mkdir -p $chpcInitPath
[ctrlr](*\#*) mount $chpcInitPath
[ctrlr](*\#*) # Restart nfs
[ctrlr](*\#*) systemctl restart nfs
[ctrlr](*\#*) 
\end{lstlisting}
%end_ohpc_run

Have ntp sync with sms node. 

% begin_ohpc_run
% ohpc_validation_newline

\begin{lstlisting}
[ctrlr](*\#*) # Restart ntp at CN
[ctrlr](*\#*) systemctl enable ntpd
[ctrlr](*\#*) # Update ntp server
[ctrlr](*\#*) cat /etc/ntp.conf | grep "server <sms_ip>"
[ctrlr](*\#*) ntp_server_exists=$?
[ctrlr](*\#*) if [ "${ntp_server_exists}" -ne "0" ]; then
[ctrlr](*\#*)     echo "server <sms_ip>" >> /etc/ntp.conf
[ctrlr](*\#*) fi
[ctrlr](*\#*) systemctl restart ntpd
[ctrlr](*\#*) # Sync time
[ctrlr](*\#*) ntpstat
[ctrlr](*\#*) #Sync sms node with compute nodes. sync users, slurm and enable munge by copying munge keys
[ctrlr](*\#*) # Sync following files to compute node
[ctrlr](*\#*) # Assuming nfs is setup properly
[ctrlr](*\#*) if [ -d $chpcInitPath ]; then
[ctrlr](*\#*)     # Update the slurm file
[ctrlr](*\#*)     cp -f -L $chpcInitPath/slurm.conf /etc/slurm/slurm.conf
[ctrlr](*\#*)     # Sync head node configuration with Compute Node
[ctrlr](*\#*)     cp -f -L $chpcInitPath/passwd /etc/passwd
[ctrlr](*\#*)     cp -f -L $chpcInitPath/group /etc/group
[ctrlr](*\#*)     cp -f -L $chpcInitPath/shadow /etc/shadow
[ctrlr](*\#*)     cp -f -L $chpcInitPath/slurm.conf /etc/slurm/slurm.conf
[ctrlr](*\#*)     cp -f -L $chpcInitPath/slurm /etc/pam.d/slurm
[ctrlr](*\#*)     cp -f -L $chpcInitPath/munge.key /etc/munge/munge.key
[ctrlr](*\#*)     # For hostname resolution
[ctrlr](*\#*)     cp -f -L $chpcInitPath/hosts /etc/hosts
[ctrlr](*\#*)     # make sure that hostname mentioned into /etc/hosts matches machine hostname. TBD
[ctrlr](*\#*)     # Start slurm and munge 
[ctrlr](*\#*)     systemctl enable munge
[ctrlr](*\#*)     systemctl restart munge
[ctrlr](*\#*)     systemctl enable slurmd
[ctrlr](*\#*)     systemctl restart slurmd
[ctrlr](*\#*) else
[ctrlr](*\#*)     logger "chpcInit:ERROR: cannot stat nfs shared /opt directory, cannot copy HPC system files"
[ctrlr](*\#*) fi
\end{lstlisting}
%end_ohpc_run
Update the hostname as per sms node.

% begin_ohpc_run
% ohpc_validation_newline

\begin{lstlisting}[language=bash,keywords={}]
[ctrlr](*\#*) # Setup hostname as per the head node
[ctrlr](*\#*) #Find the hostname of this machine from the copied over /etc/hosts file
[ctrlr](*\#*) cc_ipaddrs=(`hostname -I`)
[ctrlr](*\#*) for cc_ipaddr in ${cc_ipaddrs[@]}; do
[ctrlr](*\#*)     cat /etc/hosts | grep ${cc_ipaddr} > /dev/null
[ctrlr](*\#*)     result=$?
[ctrlr](*\#*)     if [ "$result" -eq "0" ]; then
[ctrlr](*\#*)         cc_hostname=`cat /etc/hosts | grep ${cc_ipaddr} | cut -d$'\t' -f2`
[ctrlr](*\#*)         break
[ctrlr](*\#*)     fi
[ctrlr](*\#*) done
[ctrlr](*\#*) 
[ctrlr](*\#*) if [ -z "${cc_hostname}" ]; then
[ctrlr](*\#*)     logger "chpcInit:ERROR: No resolved hostname found for any IP address in /etc/hosts"
[ctrlr](*\#*)     exit 1
[ctrlr](*\#*) fi
[ctrlr](*\#*) 
[ctrlr](*\#*) (*\#*)set the hostname
[ctrlr](*\#*) if [ $(hostname) != ${cc_hostname} ]; then
[ctrlr](*\#*)     hostnamectl set-hostname ${cc_hostname}
[ctrlr](*\#*) fi
\end{lstlisting}
%end_ohpc_run

By now all pre-requisite for slurm is taken care, lets start slurm daemon.

% begin_ohpc_run
% ohpc_validation_newline

\begin{lstlisting}[language=bash,keywords={}]
[ctrlr](*\#*) # Start slurm and munge 
[ctrlr](*\#*) systemctl enable munge
[ctrlr](*\#*) systemctl restart munge
[ctrlr](*\#*) systemctl enable slurmd
[ctrlr](*\#*) systemctl restart slurmd
\end{lstlisting}
%end_ohpc_run

One last step to make sure ssh is working and enabled on compute nodes. Update the permissions 
of ssh.

% begin_ohpc_run
% ohpc_validation_newline

\begin{lstlisting}[language=bash,keywords={}]
[ctrlr](*\#*) #Change file permissions in /etc/ssh to fix ssh into compute node
[ctrlr](*\#*) chmod 0600 /etc/ssh/ssh_host_*_key
\end{lstlisting}
%end_ohpc_run

Save the file with name chp\_cinit, we will use this file during baremetal node instance creation.

